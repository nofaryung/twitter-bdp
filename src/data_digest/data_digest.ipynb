{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "from psycopg2.extras import execute_values\n",
    "\n",
    "# Establish a connection to the database\n",
    "# Adjust the connection parameters as necessary\n",
    "conn = psycopg2.connect(\n",
    "    dbname=\"twitty\",\n",
    "    user=\"postgresuser\",\n",
    "    password=\"postgrespassword\",\n",
    "    host=\"localhost\",\n",
    "    port=\"5432\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpy @ file:///private/var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_97k4h5q73m/croot/numpy_and_numpy_base_1704311708477/work/dist/numpy-1.26.3-cp310-cp310-macosx_10_9_x86_64.whl#sha256=9d4230f09aa6cd18b645548b55fa74cb611df850cd99d39a1b636402e018c785\n"
     ]
    }
   ],
   "source": [
    "!pip freeze | grep numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_df = pd.read_csv('/Users/nofary/IDC/BDP/twitter-bdp/src/data_digest/tweets_df.csv', delimiter='\t')\n",
    "# tweets_paritioned_by_word = pd.read_csv('/Users/nofary/IDC/BDP/twitter-bdp/src/data_digest/tweets_paritioned_by_word.csv', delimiter='\t')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_df = twitter_df.replace({np.nan: None})\n",
    "twitter_df.drop(columns='Unnamed: 0',inplace=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_paritioned_by_word = twitter_df.explode('parsed_content')\n",
    "tweets_paritioned_by_word = tweets_paritioned_by_word.dropna(subset=[\"parsed_content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "def convert_to_list(row):\n",
    "    try:\n",
    "        return ast.literal_eval(row)\n",
    "    except ValueError:\n",
    "        return []\n",
    "\n",
    "\n",
    "twitter_df['parsed_content'] = twitter_df['parsed_content'].apply(convert_to_list)\n",
    "\n",
    "raw_twitter_df = list(twitter_df[['tweet_id', 'author', 'content', 'country', 'date_time', 'language', 'latitude', 'longitude', 'number_of_likes', 'number_of_shares', 'parsed_content']].itertuples(index=False, name=None))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# tweets_by_likes\n",
    "insert_tweets_by_likes = \"\"\"INSERT INTO tweets_by_likes (tweet_id, author, content, country, date_time, language, latitude, longitude, number_of_likes, number_of_shares, parsed_content) VALUES %s;\"\"\"\n",
    "execute_values(cur, insert_tweets_by_likes, raw_twitter_df)\n",
    "\n",
    "# tweets_by_share\n",
    "insert_tweets_by_share = \"\"\"INSERT INTO tweets_by_share (tweet_id, author, content, country, date_time, language, latitude, longitude, number_of_likes, number_of_shares, parsed_content) VALUES %s;\"\"\"\n",
    "execute_values(cur, insert_tweets_by_share, raw_twitter_df)\n",
    "\n",
    "# user_tweets\n",
    "insert_user_tweets = \"\"\"INSERT INTO user_tweets (tweet_id, author, content, country, date_time, language, latitude, longitude, number_of_likes, number_of_shares, parsed_content) VALUES %s;\"\"\"\n",
    "execute_values(cur, insert_user_tweets, raw_twitter_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_tweets_paritioned_by_word = list(tweets_paritioned_by_word[['tweet_id', 'author', 'content', 'country', 'date_time', 'language', 'latitude', 'longitude', 'number_of_likes', 'number_of_shares', 'parsed_content']].itertuples(index=False, name=None))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# user_tweets\n",
    "insert_tweets_by_word = \"\"\"INSERT INTO tweets_by_word (tweet_id, author, content, country, date_time, language, latitude, longitude, number_of_likes, number_of_shares, parsed_content) VALUES %s;\"\"\"\n",
    "execute_values(cur, insert_tweets_by_word, raw_tweets_paritioned_by_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # SQL command to delete all data from the table\n",
    "    delete_query = \"DELETE FROM tweets_by_likes;\"\n",
    "\n",
    "    # Execute the SQL command\n",
    "    cur.execute(delete_query)\n",
    "\n",
    "    # conn.rollback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Commit the transaction\n",
    "conn.commit()\n",
    "\n",
    "# Close the cursor and connection\n",
    "cur.close()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def convert_to_list(row):\n",
    "    try:\n",
    "        return ast.literal_eval(row)\n",
    "    except ValueError:\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def digest_data():\n",
    "    conn = None\n",
    "    cur = None\n",
    "    try:\n",
    "        # Database connection parameters from environment variables\n",
    "        # dbname = os.getenv(\"POSTGRES_DB\", \"twitty\")\n",
    "        user = os.getenv(\"POSTGRES_USER\", \"postgresuser\")\n",
    "        password = os.getenv(\"POSTGRES_PASSWORD\", \"postgrespassword\")\n",
    "        host = os.getenv(\"DB_URL\", \"localhost\")\n",
    "        port = os.getenv(\"DB_PORT\", \"5432\")\n",
    "\n",
    "        conn = psycopg2.connect(\n",
    "            dbname='twitty',\n",
    "            user=user,\n",
    "            password=password,\n",
    "            host=host\n",
    "            # port=port\n",
    "        )\n",
    "        cur = conn.cursor()\n",
    "\n",
    "        # Load and preprocess data\n",
    "        twitter_df = pd.read_csv('/Users/nofary/IDC/BDP/twitter-bdp/src/data_digest/tweets_df.csv', delimiter='\t')\n",
    "        twitter_df = twitter_df.replace({np.nan: None})\n",
    "\n",
    "        tweets_paritioned_by_word = twitter_df.explode('parsed_content')\n",
    "        tweets_paritioned_by_word = tweets_paritioned_by_word.dropna(subset=[\"parsed_content\"])\n",
    "\n",
    "        twitter_df['parsed_content'] = twitter_df['parsed_content'].apply(convert_to_list)\n",
    "\n",
    "        raw_twitter_df = list(twitter_df[['tweet_id', 'author', 'content', 'country', 'date_time', 'language', 'latitude', 'longitude', 'number_of_likes', 'number_of_shares', 'parsed_content']].itertuples(index=False, name=None))\n",
    "\n",
    "        # tweets_by_likes\n",
    "        insert_tweets_by_likes = \"\"\"INSERT INTO tweets_by_likes (tweet_id, author, content, country, date_time, language, latitude, longitude, number_of_likes, number_of_shares, parsed_content) VALUES %s;\"\"\"\n",
    "        execute_values(cur, insert_tweets_by_likes, raw_twitter_df)\n",
    "\n",
    "        # tweets_by_share\n",
    "        insert_tweets_by_share = \"\"\"INSERT INTO tweets_by_share (tweet_id, author, content, country, date_time, language, latitude, longitude, number_of_likes, number_of_shares, parsed_content) VALUES %s;\"\"\"\n",
    "        execute_values(cur, insert_tweets_by_share, raw_twitter_df)\n",
    "\n",
    "        # user_tweets\n",
    "        insert_user_tweets = \"\"\"INSERT INTO user_tweets (tweet_id, author, content, country, date_time, language, latitude, longitude, number_of_likes, number_of_shares, parsed_content) VALUES %s;\"\"\"\n",
    "        execute_values(cur, insert_user_tweets, raw_twitter_df)\n",
    "\n",
    "        # user_tweets\n",
    "        raw_tweets_paritioned_by_word = list(tweets_paritioned_by_word[['tweet_id', 'author', 'content', 'country', 'date_time', 'language', 'latitude', 'longitude', 'number_of_likes', 'number_of_shares', 'parsed_content']].itertuples(index=False, name=None))\n",
    "        insert_tweets_by_word = \"\"\"INSERT INTO tweets_by_word (tweet_id, author, content, country, date_time, language, latitude, longitude, number_of_likes, number_of_shares, parsed_content) VALUES %s;\"\"\"\n",
    "        execute_values(cur, insert_tweets_by_word, raw_tweets_paritioned_by_word)\n",
    "\n",
    "        # Commit the transaction\n",
    "        conn.commit()\n",
    "\n",
    "    except Exception as e:\n",
    "        # Rollback the transaction in case of error\n",
    "        if conn is not None:\n",
    "            conn.rollback()\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        # Optionally, re-raise the exception if you want the error to propagate\n",
    "        raise\n",
    "\n",
    "    finally:\n",
    "        # Close the cursor and connection\n",
    "        if cur is not None:\n",
    "            cur.close()\n",
    "        if conn is not None:\n",
    "            conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "digest_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
